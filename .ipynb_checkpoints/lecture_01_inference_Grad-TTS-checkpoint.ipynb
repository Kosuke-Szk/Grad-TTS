{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8688d90",
   "metadata": {},
   "source": [
    "# 演習その１ Grad-TTSを動かしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e182e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n"
     ]
    }
   ],
   "source": [
    "# Build Monotonic Alignment Search code (Cython)\n",
    "!cd model/monotonic_align; python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b0967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbddeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import torch\n",
    "\n",
    "# For Grad-TTS\n",
    "import params\n",
    "from model import GradTTS\n",
    "from text import text_to_sequence, cmudict\n",
    "from text.symbols import symbols\n",
    "from utils import intersperse\n",
    "\n",
    "# For HiFi-GAN\n",
    "import sys\n",
    "sys.path.append('./hifi-gan/')\n",
    "from env import AttrDict\n",
    "from models import Generator as HiFiGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c105fc",
   "metadata": {},
   "source": [
    "# 1.モデルのロード\n",
    "Grad-TTSによる音声合成のためには以下３つのモジュールが必要です\n",
    "## CMUDict\n",
    "文字列を音素列に変換するための辞書<br>\n",
    "入力：文字列<br>\n",
    "出力：文字列(音素列)\n",
    "<br>\n",
    "## Grad-TTS\n",
    "拡散モデルに基づいて音声合成(TextToSpeech;TTS)を行うモデル<br>\n",
    "入力：文字列(音素列)<br>\n",
    "出力：メルスペクトログラム\n",
    "<br>\n",
    "## HiFiGAN\n",
    "メルスペクトログラムから音声波形を生成するモデル<br>\n",
    "入力：メルスペクトログラム<br>\n",
    "出力：音声波\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26d106",
   "metadata": {},
   "source": [
    "## 1.1 CMUDictのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0877c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アルファベット: a 音素： ['EY1']\n",
      "アルファベット: b 音素： ['B IY1']\n",
      "アルファベット: c 音素： ['S IY1']\n"
     ]
    }
   ],
   "source": [
    "cmu = cmudict.CMUDict('./resources/cmu_dictionary')\n",
    "\n",
    "print(\"アルファベット:\", \"a\", \"音素：\", cmu.lookup(\"a\"))\n",
    "print(\"アルファベット:\", \"b\", \"音素：\", cmu.lookup(\"b\"))\n",
    "print(\"アルファベット:\", \"c\", \"音素：\", cmu.lookup(\"c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237dfcee",
   "metadata": {},
   "source": [
    "## 1.2 GradTTSのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275238b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_SPKS = 247  # 247 for Libri-TTS model and 1 for single speaker (LJSpeech)\n",
    "N_SPKS = 1\n",
    "generator = GradTTS(len(symbols)+1, N_SPKS, params.spk_emb_dim,\n",
    "                    params.n_enc_channels, params.filter_channels,\n",
    "                    params.filter_channels_dp, params.n_heads, params.n_enc_layers,\n",
    "                    params.enc_kernel, params.enc_dropout, params.window_size,\n",
    "                    params.n_feats, params.dec_dim, params.beta_min, params.beta_max,\n",
    "                    pe_scale=1000)  # pe_scale=1 for `grad-tts-old.pt`\n",
    "# generator.load_state_dict(torch.load('./checkpts/grad-tts-libri-tts.pt', map_location=lambda loc, storage: loc))\n",
    "generator.load_state_dict(torch.load('./checkpts/grad-tts.pt', map_location=lambda loc, storage: loc))\n",
    "_ = generator.cuda().eval()\n",
    "print(f'Number of parameters: {generator.nparams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c40326",
   "metadata": {},
   "source": [
    "## 1.3 HiFiGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e541138",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./checkpts/hifigan-config.json') as f:\n",
    "    h = AttrDict(json.load(f))\n",
    "hifigan = HiFiGAN(h)\n",
    "hifigan.load_state_dict(torch.load('./checkpts/hifigan.pt', map_location=lambda loc, storage: loc)['generator'])\n",
    "_ = hifigan.cuda().eval()\n",
    "hifigan.remove_weight_norm()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ce6fb",
   "metadata": {},
   "source": [
    "# 2.音声生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Here are the match lineups for the Colombia Haiti match.\"\n",
    "# text = \"I'm looking forward to seeing you again.\"\n",
    "text = \"Hello. I am an artificial intelligence for voice generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(intersperse(text_to_sequence(text, dictionary=cmu), len(symbols))).cuda()[None]\n",
    "x_lengths = torch.LongTensor([x.shape[-1]]).cuda()\n",
    "x.shape, x_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dt.datetime.now()\n",
    "y_enc, y_dec, attn = generator.forward(x, x_lengths, n_timesteps=50, temperature=1.3,\n",
    "                                       stoc=False, spk=None if N_SPKS==1 else torch.LongTensor([15]).cuda(),\n",
    "                                       length_scale=0.91)\n",
    "t = (dt.datetime.now() - t).total_seconds()\n",
    "print(f'Grad-TTS RTF: {t * 22050 / (y_dec.shape[-1] * 256)}')\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Encoder outputs')\n",
    "plt.imshow(y_enc.cpu().squeeze(), aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Decoder outputs')\n",
    "plt.imshow(y_dec.cpu().squeeze(), aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Alignment')\n",
    "plt.imshow(attn.cpu().squeeze(), aspect='auto', origin='lower');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = hifigan.forward(y_dec).cpu().squeeze().clamp(-1, 1)\n",
    "ipd.display(ipd.Audio(audio, rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bd93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
